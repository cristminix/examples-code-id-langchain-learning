{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad1396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic OpenAI-compatible endpoint using ChatOpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "import os\n",
    "default_model_name = os.environ[\"OPENAI_MODEL\"]\n",
    "pg_connection = os.environ[\"PGVECTOR_CONNECTION_STRING\"]\n",
    "llm = ChatOpenAI(model=default_model_name,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cee803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil konek dengan collection 'langchain'\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_postgres.vectorstores import PGVector\n",
    " \n",
    " \n",
    "# embed each chunk and insert it into the vector store\n",
    "embeddings_model = OllamaEmbeddings(model=\"nomic-embed-text\",base_url=\"http://localhost:11434\")\n",
    "# Coba dengan nama default\n",
    "try:\n",
    "    db = PGVector.from_existing_index(\n",
    "        embedding=embeddings_model,\n",
    "        collection_name=\"langchain\",  # Coba default\n",
    "        connection=pg_connection,\n",
    "    )\n",
    "    print(\"Berhasil konek dengan collection 'langchain'\")\n",
    "except Exception as e1:\n",
    "    print(f\"Collection 'langchain' tidak ditemukan: {e1}\")\n",
    "    \n",
    "    # Coba dengan nama lain yang mungkin\n",
    "    try:\n",
    "        db = PGVector.from_existing_index(\n",
    "            embedding=embeddings_model,\n",
    "            collection_name=\"nomic-embed-text\",  # Nama model\n",
    "            connection=pg_connection,\n",
    "        )\n",
    "        print(\"Berhasil konek dengan collection 'nomic-embed-text'\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Collection 'nomic-embed-text' tidak ditemukan: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40c715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1a5729c5-d51d-411e-bb18-4a7db6161250', metadata={'source': '../../tesla.md'}, page_content='Use of Estimates'),\n",
       " Document(id='0897e365-990b-48b9-9748-c6e76f0ca622', metadata={'source': '../../tesla.md'}, page_content='---\\n\\n Warranties'),\n",
       " Document(id='48b06a60-2f92-4f82-9eea-40d91831436f', metadata={'source': '../../tesla.md'}, page_content='---\\n\\n Warranties'),\n",
       " Document(id='175eb83c-c4f7-47dd-9311-40f56f7c6be0', metadata={'source': '../../tesla.md'}, page_content='Stock-Based Compensation')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"Q3\", k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195c0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q:produk tesla\n",
      "Berdasarkan dokumen yang tersedia, produk Tesla meliputi:\n",
      "\n",
      "1. **Kendaraan listrik berkinerja tinggi** - kendaraan bermotor listrik penuh (fully electric vehicles) yang dirancang, dikembangkan, diproduksi, dijual dan disewakan.\n",
      "\n",
      "2. **Sistem pembangkit dan penyimpanan energi** - sistem terkait energi yang juga dirancang dan dikembangkan oleh Tesla.\n",
      "\n",
      "Tesla menjual produk-produknya secara langsung kepada pelanggan dan menekankan pada kinerja, desain yang menarik, serta keselamatan pengguna dan tenaga kerja dalam proses desain dan produksi. Selain itu, Tesla juga terus mengembangkan teknologi mengemudi otomatis penuh untuk meningkatkan keselamatan.\n"
     ]
    }
   ],
   "source": [
    "# create retriever\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Always answer in indonesian language.Answer the question based only on\n",
    "    the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "chain = prompt | llm\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(\"\"\"Provide a better search\n",
    "    query for web search engine to answer the given question, end the queries\n",
    "    with '**'.\n",
    "    examples:\n",
    "    Question: Minyak\n",
    "    Answer: Jenis Minyak**\n",
    "    Question: {x} Answer:\"\"\")\n",
    "\n",
    "def parse_rewriter_output(message):\n",
    "    return message.content.strip('\"').strip(\"**\")\n",
    "\n",
    "rewriter = rewrite_prompt | llm | parse_rewriter_output\n",
    "\n",
    " \n",
    "def qa_rrr(input):\n",
    "    # rewrite the query\n",
    "    new_query = rewriter.invoke(input)\n",
    "    print(f\"q:{new_query}\")\n",
    "    # fetch relevant documents\n",
    "    docs = retriever.get_relevant_documents(new_query)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    " \n",
    "result=qa_rrr(\"produk tesla?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6913a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berdasarkan dokumen yang tersedia, produk Tesla mencakup:\n",
      "\n",
      "1. Kendaraan listrik berperforma tinggi.\n",
      "2. Sistem pembangkit dan penyimpanan energi.\n",
      "3. Layanan-layanan yang terkait dengan produk-produk tersebut.\n",
      "\n",
      "Tesla menjual produknya secara langsung kepada konsumen dan terus mengembangkan infrastruktur layanan pelanggan, termasuk jaringan pusat layanan kendaraan, layanan mobil (Mobile Service), bengkel perbaikan badan kendaraan, serta stasiun pengisian daya Supercharger dan Destination Charger. Perusahaan ini menekankan aspek performa, desain yang menarik, serta keselamatan pengguna dan tenaga kerja dalam proses desain dan produksi. Selain itu, Tesla juga terus mengembangkan teknologi mengemudi otomatis guna meningkatkan keselamatan.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Always answer in indonesian language.Answer the question based only on\n",
    "    the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "perspectives_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an AI language model assistant. Your task is to generate five different versions \n",
    "    of the given user question to retrieve relevant documents from a vector database.\n",
    "    By generating multiple perspectives on the user question, your goal is to help the user \n",
    "    overcome some of the limitations of the distance-based similarity search. Provide these \n",
    "    alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    ")\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "query_gen = perspectives_prompt | llm | parse_queries_output\n",
    "\n",
    "def get_unique_union(document_lists):\n",
    "    # Flatten list of lists, and dedupe them\n",
    "    deduped_docs = {\n",
    "        doc.page_content: doc\n",
    "        for sublist in document_lists for doc in sublist\n",
    "    }\n",
    "    # return a flat list of unique docs\n",
    "    return list(deduped_docs.values())\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | get_unique_union\n",
    "\n",
    "def multi_query_qa(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retrieval_chain.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "result=multi_query_qa(\"produk tesla?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a873ce9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# Ambil dokumen yang sesuai untuk setiap doc_str\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     52\u001b[39m         documents[doc_str]\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m doc_str \u001b[38;5;129;01min\u001b[39;00m reranked_doc_strs\n\u001b[32m     54\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m retrieval_chain = query_gen | \u001b[43mretriever\u001b[49m.batch | reciprocal_rank_fusion\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Pemakaian\u001b[39;00m\n\u001b[32m     59\u001b[39m docs=retrieval_chain.invoke({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mcabe hujau?\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[31mNameError\u001b[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "#---------------------- START DISINI -------------------------------------\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(\"\"\"Anda adalah asisten\n",
    "    yang berguna untuk menghasilkan beberapa kata kunci pencarian berdasarkan\n",
    "    satu pertanyaan masukan. \\n\n",
    "    Buatlah beberapa kata kunci pencarian yang berkaitan dengan: {question} \\n\n",
    "    Hasil (4 kueri):\"\"\")\n",
    "\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "\n",
    "query_gen = prompt_rag_fusion | llm | parse_queries_output\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Reciprocal Rank Fusion (RRF) diterapkan pada beberapa daftar dokumen \n",
    "       yang telah diperingkat, dengan parameter opsional k yang digunakan \n",
    "       dalam rumus RRF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inisialisasi dictionary untuk menyimpan skor gabungan setiap dokumen\n",
    "    # Dokumen akan diindeks berdasarkan isinya untuk memastikan keunikan\n",
    "    fused_scores = {}\n",
    "    documents = {}\n",
    "\n",
    "    # Iterasi melalui setiap daftar dokumen yang telah diperingkat\n",
    "    for docs in results:\n",
    "        # Iterasi melalui setiap dokumen dalam daftar,\n",
    "        # beserta peringkatnya (posisi dalam daftar)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Gunakan isi dokumen sebagai kunci untuk memastikan keunikan\n",
    "            doc_str = doc.page_content\n",
    "            # Jika dokumen belum pernah ditemukan sebelumnya,\n",
    "            # - inisialisasi skor ke 0\n",
    "            # - simpan untuk digunakan nanti\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                documents[doc_str] = doc\n",
    "            # Perbarui skor dokumen menggunakan rumus RRF:\n",
    "            # 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Urutkan dokumen berdasarkan skor gabungan secara menurun\n",
    "    # untuk mendapatkan hasil peringkat ulang akhir\n",
    "    reranked_doc_strs = sorted(\n",
    "        fused_scores, key=lambda d : fused_scores[d], reverse=True\n",
    "    )\n",
    "    # Ambil dokumen yang sesuai untuk setiap doc_str\n",
    "    return [\n",
    "        documents[doc_str]\n",
    "        for doc_str in reranked_doc_strs\n",
    "    ]\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion\n",
    "\n",
    "# Pemakaian\n",
    "docs=retrieval_chain.invoke({\"question\":\"cabe hujau?\"})\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f30f5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla, Inc. adalah perusahaan yang didirikan di Negara Bagian Delaware pada tanggal 1 Juli 2003. Perusahaan ini bergerak dalam desain, pengembangan, manufaktur, penjualan, dan pemesanan kendaraan listrik berkinerja tinggi serta sistem pembangkit dan penyimpanan energi. Selain itu, Tesla juga menawarkan layanan-layanan terkait produk-produknya. Perusahaan dipimpin oleh Chief Executive Officer yang bertindak sebagai chief operating decision maker (CODM), dan perusahaan dikelola dalam dua segmen operasional utama, yaitu otomotif dan energi pembangkit serta penyimpanan.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(\"\"\"Tolong tulis sebuah paragraf untuk\n",
    "   menjawab pertanyaan.\\n Pertanyaan: {question} \\n Paragraf:\"\"\")\n",
    "\n",
    "generate_doc = (\n",
    "    prompt_hyde | llm | StrOutputParser()\n",
    ")\n",
    "# generate_doc.invoke({\"question\":\"Siapa elon?\"})\n",
    "retrieval_chain = generate_doc | retriever\n",
    "# retrieval_chain.invoke({\"question\":\"Siapa elon?\"})\n",
    "\n",
    "def qa(input):\n",
    "  # ambil dokumen relevan dari rantai pengambilan hyde yang didefinisikan sebelumnya\n",
    "  docs = retrieval_chain.invoke(input)\n",
    "  # format prompt\n",
    "  formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "  # buat jawaban\n",
    "  chain = llm|StrOutputParser()\n",
    "  answer = chain.invoke(formatted)\n",
    "  return answer\n",
    "\n",
    "qa(\" tesla?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d4ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='8817e773-4adb-4b19-841d-dfeff0852c3a', metadata={'source': '../../test.txt'}, page_content='Pemanenan Cabai: Teknik dan Penanganan Pasca Panen\\nIndikator dan Teknik Panen\\nCabai dapat dipanen pada beberapa tahap kematangan tergantung tujuan pasar:\\n\\nCabai hijau - dipanen 70-80 hari setelah tanam, sebelum perubahan warna\\n\\nCabai merah segar - dipanen 85-100 hari setelah tanam, ketika 80-90% permukaan sudah merah\\n\\nCabai untuk bibit - dipanen pada kematangan fisiologis penuh\\n\\nPemanenan sebaiknya dilakukan pagi hari setelah embun kering atau sore hari untuk mengurangi stres tanaman. Gunakan gunting atau pisau tajam untuk memotong tangkai buah, meninggalkan sedikit tangkai pada buah untuk memperpanjang masa simpan.\\n\\nPenanganan Pasca Panen\\nPenanganan pasca panen yang tepat menentukan kualitas akhir cabai:\\n\\nSortasi - memisahkan buah berdasarkan ukuran, warna, dan kondisi\\n\\nPencucian - membersihkan kotoran dengan air mengalir, diikuti pengeringan\\n\\nPengemasan - menggunakan kemasan yang memungkinkan sirkulasi udara'), Document(id='a594677f-483a-4d1c-a668-86f8b38d9ccf', metadata={'source': '../../test.txt'}, page_content='Panduan Lengkap Budidaya dan Pemanenan Cabai\\nPenyemaian Benih Cabai yang Efektif\\nPenyemaian adalah tahap kritis dalam budidaya cabai yang menentukan kualitas bibit dan produktivitas tanaman. Proses ini memerlukan ketelitian dan pemahaman tentang kondisi optimal untuk perkecambahan benih cabai.\\n\\nTeknik Penyemaian Modern\\nPenyemaian cabai diawali dengan pemilihan benih berkualitas dari varietas unggul yang sesuai dengan kondisi lokal. Benih cabai umumnya memerlukan perlakuan khusus sebelum disemai, seperti perendaman dalam air hangat (50-55Â°C) selama 30 menit untuk memecah dormansi dan mengurangi patogen.\\n\\nMedia semai yang ideal terdiri dari campuran tanah subur, pupuk kandang matang, dan sekam padi dengan perbandingan 2:1:1. Media ini harus disterilisasi terlebih dahulu untuk mencegah penyakit tular tanah seperti rebah semai (damping off). Penggunaan tray semai atau polybag kecil dengan diameter 5-7 cm telah menjadi standar praktis untuk memudahkan pengelolaan dan transplantasi.'), Document(id='5e2c2cc8-3ded-41ae-946a-08e00df69d4e', metadata={'source': '../../tesla.md'}, page_content='|         |  |                                                                                                                                                                                                                                                                                                                                                                                                                                                            |  |                           |  |           |  |         |  |                  |  |          |'), Document(id='8c1fee9d-7c4f-4528-9453-c0be0cfd568b', metadata={'source': '../../tesla.md'}, page_content='|         |  |                                                                                                                                                                                                                                                                                                                                                                                                                                                            |  |                           |  |           |  |         |  |                  |  |          |')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "fields = [\n",
    "    # AttributeInfo(\n",
    "    #     name=\"genre\",\n",
    "    #     description=\"Genre film\",\n",
    "    #     type=\"string or list[string]\",\n",
    "    # ),\n",
    "    # AttributeInfo(\n",
    "    #     name=\"year\",\n",
    "    #     description=\"Tahun film dirilis\",\n",
    "    #     type=\"integer\",\n",
    "    # ),\n",
    "    # AttributeInfo(\n",
    "    #     name=\"director\",\n",
    "    #     description=\"Nama sutradara film\",\n",
    "    #     type=\"string\",\n",
    "    # ),\n",
    "    # AttributeInfo(\n",
    "    #     name=\"rating\", description=\"Penilaian film 1-10\", type=\"float\"\n",
    "    # ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"Nama source file\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "description = \"Ringkasan laporan\"\n",
    "\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, db, description, fields,\n",
    ")\n",
    "\n",
    "print(retriever.invoke(\"Cabe hijau?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee3ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('For Those About To Rock (We Salute You)',), ('Balls to the Wall',), ('Fast As a Shark',), ('Restless and Wild',), ('Princess of the Dawn',)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains.sql_database.query import create_sql_query_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ganti ini dengan detail koneksi db Anda\n",
    "db = SQLDatabase.from_uri(\"sqlite:////mnt/data/userdata/books/learning-langchain/examples/ch02/Chinook.db\")\n",
    "prompt_sql = ChatPromptTemplate.from_template(\"\"\"\n",
    "Sebutkan kueri SQL untuk menjawab pertanyaan berikut.\n",
    "Gunakan dialek: {dialect}\n",
    "Tampilkan maksimal {top_k} hasil saja.\n",
    "\n",
    "PENTING: Berikan HANYA kueri SQL saja, tanpa tanda backtick, tanpa tulisan \"sql\", dan tanpa penjelasan apapun. \n",
    "Langsung mulai dengan SELECT.\n",
    "\n",
    "Berikut adalah struktur tabelnya:\n",
    "{table_info}\n",
    "\n",
    "Pertanyaan: {input}\n",
    "Kueri SQL:\"\"\")\n",
    "\n",
    "# Sekarang panggil chain-nya\n",
    "write_query = create_sql_query_chain(llm, db, prompt=prompt_sql)\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "chain = write_query | execute_query\n",
    "\n",
    "# LangChain akan otomatis mengisi {dialect}, {table_info}, dan {top_k}\n",
    "question = \"Tampilkan daftar produk\"\n",
    "hasil = chain.invoke({\"input\": question,\"question\": question})\n",
    "print(hasil)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "examples-code-id-langchain-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
