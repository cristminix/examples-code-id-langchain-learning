{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad1396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic OpenAI-compatible endpoint using ChatOpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "import os\n",
    "default_model_name = os.environ[\"OPENAI_MODEL\"]\n",
    "pg_connection = os.environ[\"PGVECTOR_CONNECTION_STRING\"]\n",
    "llm = ChatOpenAI(model=default_model_name,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cee803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil konek dengan collection 'langchain'\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_postgres.vectorstores import PGVector\n",
    " \n",
    " \n",
    "# embed each chunk and insert it into the vector store\n",
    "embeddings_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "# Coba dengan nama default\n",
    "try:\n",
    "    db = PGVector.from_existing_index(\n",
    "        embedding=embeddings_model,\n",
    "        collection_name=\"langchain\",  # Coba default\n",
    "        connection=pg_connection,\n",
    "    )\n",
    "    print(\"Berhasil konek dengan collection 'langchain'\")\n",
    "except Exception as e1:\n",
    "    print(f\"Collection 'langchain' tidak ditemukan: {e1}\")\n",
    "    \n",
    "    # Coba dengan nama lain yang mungkin\n",
    "    try:\n",
    "        db = PGVector.from_existing_index(\n",
    "            embedding=embeddings_model,\n",
    "            collection_name=\"nomic-embed-text\",  # Nama model\n",
    "            connection=pg_connection,\n",
    "        )\n",
    "        print(\"Berhasil konek dengan collection 'nomic-embed-text'\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Collection 'nomic-embed-text' tidak ditemukan: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1677ab38-7604-4515-869a-ddf06cf5bae8', metadata={'source': '../../tesla.md'}, page_content='---\\n\\n PART III\\n\\nITEM 10\\\\. DIRECTORS, EXECUTIVE OFFICERS AND CORPORATE GOVERNANCE\\n\\nThe information required by this Item 10 of Form 10-K will be included in our 2023 Proxy Statement to be filed with the Securities and Exchange Commission in connection with the solicitation of proxies for our 2023 Annual Meeting of Stockholders and is incorporated herein by reference. The 2023 Proxy Statement will be filed with the Securities and Exchange Commission within 120 days after the end of the fiscal year to which this report relates. \\n\\nITEM 11\\\\. EXECUTIVE COMPENSATION\\n\\nThe information required by this Item 11 of Form 10-K will be included in our 2023 Proxy Statement and is incorporated herein by reference. \\n\\nITEM 12\\\\. SECURITY OWNERSHIP OF CERTAIN BENEFICIAL OWNERS AND MANAGEMENT AND RELATED STOCKHOLDER MATTERS\\n\\nThe information required by this Item 12 of Form 10-K will be included in our 2023 Proxy Statement and is incorporated herein by reference.'),\n",
       " Document(id='980bb6a3-b27a-4c24-b797-1edeaca1cd99', metadata={'source': '../../tesla.md'}, page_content='---\\n\\n Note 3 – Digital Assets, Net'),\n",
       " Document(id='1d371111-68cd-4c63-a54b-e9c0600e3516', metadata={'source': '../../tesla.md'}, page_content='and varying levels of inflation, we currently expect our capital expenditures to be between $6.00 to $8.00 billion in 2023 and between $7.00 to $9.00 billion in each of the following two fiscal years.'),\n",
       " Document(id='e97c37f8-9ca4-4ea9-859f-1946862005f9', metadata={'source': '../../tesla.md'}, page_content='| 10.48   |  | [Third Amendment to Amended and Restated Agreement For Research & Development Alliance on Triex Module Technology, effective as of February 12, 2015, by and between The Research Foundation For The State University of New York, on behalf of the College of Nanoscale Science and Engineering of the State University of New York, and Silevo, Inc.](https://www.sec.gov/Archives/edgar/data/1408356/000156459015003352/scty-ex1016c%5F20150331365.htm) |  | 10-Q(1)                   |  | 001-35758 |  | 10.16c  |  | May 6, 2015      |  |          |')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"Q3\", k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q:Daftar Produk Tesla lengkap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristminix/tmp-dir/ipykernel_1686218/3860650886.py:40: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  docs = retriever.get_relevant_documents(new_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berdasarkan dokumen yang tersedia, produk Tesla meliputi:\n",
      "\n",
      "1. **Kendaraan listrik** (mobil Tesla) — baik baru maupun bekas, yang dilengkapi dengan jaminan terbatas pabrikan dan rencana layanan diperpanjang untuk beberapa model di wilayah tertentu.\n",
      "2. **Produk energi** — termasuk sistem penyimpanan energi (seperti baterai rumah), yang juga disertai jaminan terbatas serta layanan perbaikan.\n",
      "\n",
      "Selain itu, Tesla juga menyediakan layanan pemasangan untuk sistem energi tersebut, lengkap dengan jaminan terhadap pekerjaan instalasi.\n"
     ]
    }
   ],
   "source": [
    "# create retriever\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Always answer in indonesian language.Answer the question based only on\n",
    "    the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "chain = prompt | llm\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(\"\"\"Provide a better search\n",
    "    query for web search engine to answer the given question, end the queries\n",
    "    with '**'.\n",
    "    examples:\n",
    "    Question: Minyak\n",
    "    Answer: Jenis Minyak**\n",
    "    Question: {x} Answer:\"\"\")\n",
    "\n",
    "def parse_rewriter_output(message):\n",
    "    return message.content.strip('\"').strip(\"**\")\n",
    "\n",
    "rewriter = rewrite_prompt | llm | parse_rewriter_output\n",
    "\n",
    " \n",
    "def qa_rrr(input):\n",
    "    # rewrite the query\n",
    "    new_query = rewriter.invoke(input)\n",
    "    print(f\"q:{new_query}\")\n",
    "    # fetch relevant documents\n",
    "    docs = retriever.get_relevant_documents(new_query)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    " \n",
    "result=qa_rrr(\"Apa saja produk TESLA?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6913a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabai hijau adalah jenis cabai yang dipanen pada tahap awal kematangan, sebelum terjadi perubahan warna pada buah. Berdasarkan informasi dari dokumen, cabai hijau biasanya dipanen sekitar 70-80 hari setelah tanam. Pemanenan dilakukan pagi hari setelah embun kering atau sore hari untuk mengurangi stres pada tanaman. Untuk memastikan kualitas dan memperpanjang masa simpan, gunting atau pisau tajam digunakan untuk memotong tangkai buah, dengan meninggalkan sedikit tangkai pada buah.\n",
      "\n",
      "Selain itu, penanganan pasca panen yang baik juga penting untuk menjaga kualitas cabai hijau, termasuk sortasi berdasarkan ukuran, warna, dan kondisi buah, pencucian untuk membersihkan kotoran, serta pengemasan yang memungkinkan sirkulasi udara.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Always answer in indonesian language.Answer the question based only on\n",
    "    the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "perspectives_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an AI language model assistant. Your task is to generate five different versions \n",
    "    of the given user question to retrieve relevant documents from a vector database.\n",
    "    By generating multiple perspectives on the user question, your goal is to help the user \n",
    "    overcome some of the limitations of the distance-based similarity search. Provide these \n",
    "    alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    ")\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "query_gen = perspectives_prompt | llm | parse_queries_output\n",
    "\n",
    "def get_unique_union(document_lists):\n",
    "    # Flatten list of lists, and dedupe them\n",
    "    deduped_docs = {\n",
    "        doc.page_content: doc\n",
    "        for sublist in document_lists for doc in sublist\n",
    "    }\n",
    "    # return a flat list of unique docs\n",
    "    return list(deduped_docs.values())\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | get_unique_union\n",
    "\n",
    "def multi_query_qa(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retrieval_chain.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "result=multi_query_qa(\"cabe hujau?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a873ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='5e2c2cc8-3ded-41ae-946a-08e00df69d4e', metadata={'source': '../../tesla.md'}, page_content='|         |  |                                                                                                                                                                                                                                                                                                                                                                                                                                                            |  |                           |  |           |  |         |  |                  |  |          |'), Document(id='8817e773-4adb-4b19-841d-dfeff0852c3a', metadata={'source': '../../test.txt'}, page_content='Pemanenan Cabai: Teknik dan Penanganan Pasca Panen\\nIndikator dan Teknik Panen\\nCabai dapat dipanen pada beberapa tahap kematangan tergantung tujuan pasar:\\n\\nCabai hijau - dipanen 70-80 hari setelah tanam, sebelum perubahan warna\\n\\nCabai merah segar - dipanen 85-100 hari setelah tanam, ketika 80-90% permukaan sudah merah\\n\\nCabai untuk bibit - dipanen pada kematangan fisiologis penuh\\n\\nPemanenan sebaiknya dilakukan pagi hari setelah embun kering atau sore hari untuk mengurangi stres tanaman. Gunakan gunting atau pisau tajam untuk memotong tangkai buah, meninggalkan sedikit tangkai pada buah untuk memperpanjang masa simpan.\\n\\nPenanganan Pasca Panen\\nPenanganan pasca panen yang tepat menentukan kualitas akhir cabai:\\n\\nSortasi - memisahkan buah berdasarkan ukuran, warna, dan kondisi\\n\\nPencucian - membersihkan kotoran dengan air mengalir, diikuti pengeringan\\n\\nPengemasan - menggunakan kemasan yang memungkinkan sirkulasi udara')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#---------------------- START DISINI -------------------------------------\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(\"\"\"Anda adalah asisten\n",
    "    yang berguna untuk menghasilkan beberapa kata kunci pencarian berdasarkan\n",
    "    satu pertanyaan masukan. \\n\n",
    "    Buatlah beberapa kata kunci pencarian yang berkaitan dengan: {question} \\n\n",
    "    Hasil (4 kueri):\"\"\")\n",
    "\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "\n",
    "query_gen = prompt_rag_fusion | llm | parse_queries_output\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Reciprocal Rank Fusion (RRF) diterapkan pada beberapa daftar dokumen \n",
    "       yang telah diperingkat, dengan parameter opsional k yang digunakan \n",
    "       dalam rumus RRF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inisialisasi dictionary untuk menyimpan skor gabungan setiap dokumen\n",
    "    # Dokumen akan diindeks berdasarkan isinya untuk memastikan keunikan\n",
    "    fused_scores = {}\n",
    "    documents = {}\n",
    "\n",
    "    # Iterasi melalui setiap daftar dokumen yang telah diperingkat\n",
    "    for docs in results:\n",
    "        # Iterasi melalui setiap dokumen dalam daftar,\n",
    "        # beserta peringkatnya (posisi dalam daftar)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Gunakan isi dokumen sebagai kunci untuk memastikan keunikan\n",
    "            doc_str = doc.page_content\n",
    "            # Jika dokumen belum pernah ditemukan sebelumnya,\n",
    "            # - inisialisasi skor ke 0\n",
    "            # - simpan untuk digunakan nanti\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                documents[doc_str] = doc\n",
    "            # Perbarui skor dokumen menggunakan rumus RRF:\n",
    "            # 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Urutkan dokumen berdasarkan skor gabungan secara menurun\n",
    "    # untuk mendapatkan hasil peringkat ulang akhir\n",
    "    reranked_doc_strs = sorted(\n",
    "        fused_scores, key=lambda d : fused_scores[d], reverse=True\n",
    "    )\n",
    "    # Ambil dokumen yang sesuai untuk setiap doc_str\n",
    "    return [\n",
    "        documents[doc_str]\n",
    "        for doc_str in reranked_doc_strs\n",
    "    ]\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion\n",
    "\n",
    "# Pemakaian\n",
    "docs=retrieval_chain.invoke({\"question\":\"cabe hujau?\"})\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30f5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berdasarkan dokumen yang diberikan, Tesla adalah sebuah perusahaan yang berfokus pada percepatan transisi dunia menuju energi berkelanjutan. Tujuan utama Tesla adalah mengatasi emisi karbon dengan menyediakan ekosistem energi dan transportasi yang lengkap melalui desain dan manufaktur kendaraan listrik serta produk penyimpanan energi.\\n\\nTesla memproduksi berbagai jenis kendaraan listrik, termasuk mobil penumpang seperti Model S, Model 3, Model X, dan Model Y, serta kendaraan komersial seperti Tesla Semi. Selain itu, Tesla juga merencanakan pengembangan kendaraan listrik spesial seperti Cybertruck dan Tesla Roadster baru.\\n\\nPerusahaan ini juga memproduksi produk penyimpanan energi berbasis baterai lithium-ion, yaitu Powerwall untuk rumah atau fasilitas komersial kecil, serta Megapack untuk pelanggan komersial, industri, utilitas, dan pembangkit energi. Produk-produk ini dirancang untuk mendukung sistem energi terbarukan dan meningkatkan efisiensi operasional pabrik-pabrik Tesla secara berkelanjutan.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(\"\"\"Tolong tulis sebuah paragraf untuk\n",
    "   menjawab pertanyaan.\\n Pertanyaan: {question} \\n Paragraf:\"\"\")\n",
    "\n",
    "generate_doc = (\n",
    "    prompt_hyde | llm | StrOutputParser()\n",
    ")\n",
    "# generate_doc.invoke({\"question\":\"Siapa elon?\"})\n",
    "retrieval_chain = generate_doc | retriever\n",
    "# retrieval_chain.invoke({\"question\":\"Siapa elon?\"})\n",
    "\n",
    "def qa(input):\n",
    "  # ambil dokumen relevan dari rantai pengambilan hyde yang didefinisikan sebelumnya\n",
    "  docs = retrieval_chain.invoke(input)\n",
    "  # format prompt\n",
    "  formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "  # buat jawaban\n",
    "  chain = llm|StrOutputParser()\n",
    "  answer = chain.invoke(formatted)\n",
    "  return answer\n",
    "\n",
    "qa(\"Siapa tesla?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
