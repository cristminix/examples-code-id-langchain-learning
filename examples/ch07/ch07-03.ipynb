{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ad1396c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generic OpenAI-compatible endpoint using ChatOpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import os\n",
        "default_model_name = os.environ[\"OPENAI_MODEL\"]\n",
        "pg_connection = os.environ[\"PGVECTOR_CONNECTION_STRING\"]\n",
        "llm = ChatOpenAI(model=default_model_name,temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ba57df16",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class SupervisorDecision(BaseModel):\n",
        "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
        "\n",
        "model = llm\n",
        "model = model.with_structured_output(SupervisorDecision)\n",
        "\n",
        "agents = [\"researcher\", \"coder\"]\n",
        "\n",
        "system_prompt_part_1 = f\"\"\"Anda adalah pengawas yang ditugaskan mengelola\n",
        "percakapan antara pekerja berikut: {agents}. Mengingat permintaan pengguna berikut,\n",
        "tanggapi dengan pekerja yang akan bertindak berikutnya. Setiap pekerja akan melakukan\n",
        "tugas dan menanggapi dengan hasil dan status mereka. Ketika selesai,\n",
        "tanggapi dengan FINISH.\"\"\"\n",
        "\n",
        "system_prompt_part_2 = f\"\"\"Mengingat percakapan di atas, siapa yang harus bertindak berikutnya? Atau\n",
        "haruskah kita FINISH? Pilih salah satu: {', '.join(agents)}, FINISH\"\"\"\n",
        "\n",
        "def supervisor(state):\n",
        "    messages = [\n",
        "        (\"system\", system_prompt_part_1),\n",
        "        *state[\"messages\"],\n",
        "        (\"system\", \tsystem_prompt_part_2)\n",
        "    ]\n",
        "    return model.invoke(messages)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "examples-code-id-langchain-learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
