{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "generic-configuration",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generic OpenAI-compatible endpoint using ChatOpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage,SystemMessage\n",
        "import os\n",
        "default_model_name = os.environ[\"OPENAI_MODEL\"]\n",
        "llm = ChatOpenAI(model=default_model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6d58b398",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is **Paris**.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 27, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 7}, 'words': 52}, 'model_name': 'zai', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f47a941d-fd4f-4932-83c5-4de600cc733c-0')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [HumanMessage(\"What is the capital of France?\")]\n",
        "llm.invoke(messages) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dca7c598",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris!!!', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 32, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}, 'words': 50}, 'model_name': 'zai', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-16b4fee3-44e8-4b66-ae02-9a95642c0913-0')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "system_msg = SystemMessage(\n",
        "    '''You are a helpful assistant that responds to questions with three\n",
        "        exclamation marks.'''\n",
        ")\n",
        "messages = [system_msg,HumanMessage(\"What is the capital of France?\")]\n",
        "llm.invoke(messages) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3f5a0200",
      "metadata": {},
      "outputs": [],
      "source": [
        "context=\"\"\"Kemajuan terbaru dalam NLP didorong oleh Large Language Models\n",
        "(LLM). Model-model ini mengungguli model-model yang lebih kecil dan telah\n",
        "menjadi sangat berharga bagi para pengembang yang membuat aplikasi dengan\n",
        "kemampuan NLP. Pengembang dapat mengakses model-model ini melalui library\n",
        "`transformers` dari Hugging Face, atau dengan memanfaatkan layanan dari OpenAI\n",
        "dan Cohere melalui library `openai` dan `cohere`.\"\"\"\n",
        "question=\"Penyedia model mana saja yang menawarkan LLM?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ae304344",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Berdasarkan konteks yang diberikan, penyedia model yang menawarkan LLM antara lain:\n",
            "\n",
            "1. **Hugging Face** (melalui library `transformers`)\n",
            "2. **OpenAI** (melalui library `openai`)\n",
            "3. **Cohere** (melalui library `cohere`)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    ('system', '''Answer the question based on the context below. If the\n",
        "        question cannot be answered using the information provided, answer with\n",
        "        \"I don\\'t know\".'''),\n",
        "    ('human', 'Context: {context}'),\n",
        "    ('human', 'Question: {question}'),\n",
        "])\n",
        "chain = template | llm\n",
        "result=chain.invoke({\n",
        "    \"context\":context,\n",
        "    \"question\":question\n",
        "})\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "02ac20e9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Berdasarkan konteks yang diberikan, penyedia model yang menawarkan LLM antara lain:\n",
            "\n",
            "1. **Hugging Face** - melalui library `transformers`.\n",
            "2. **OpenAI** - melalui layanan dan library `openai`.\n",
            "3. **Cohere** - melalui layanan dan library `cohere`.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = PromptTemplate.from_template(\"\"\"Jawab pertanyaan berdasarkan konteks\n",
        "    di bawah ini. Jika pertanyaan tidak dapat dijawab menggunakan informasi\n",
        "    yang diberikan, jawab dengan \"Saya tidak tahu\".\n",
        "\n",
        "Konteks: {context}\n",
        "\n",
        "Pertanyaan: {question}\n",
        "\n",
        "Jawaban: \"\"\")\n",
        "\n",
        "result=chain.invoke({\n",
        "    \"context\":context,\n",
        "    \"question\":question\n",
        "})\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eae870b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: Keduanya sama berat.\n",
            "Justifikasi: Satu pon batu bata dan satu pon bulu memiliki berat yang sama, yaitu satu pon. Meskipun volume bulu jauh lebih besar daripada batu bata, beratnya tetap sama karena keduanya diukur dalam satuan yang sama (pon).\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "\n",
        "class JustifiedAnswer(BaseModel):\n",
        "    '''Jawaban atas pertanyaan pengguna beserta justifikasi untuk jawaban tersebut.'''\n",
        "    jawaban: str\n",
        "    '''Jawaban atas pertanyaan pengguna'''\n",
        "    justifikasi: str\n",
        "    '''Justifikasi untuk jawaban'''\n",
        "\n",
        "structured_llm = llm.with_structured_output(JustifiedAnswer)\n",
        "\n",
        "result=structured_llm.invoke(\"\"\"Mana yang lebih berat, satu pon batu bata atau satu pon bulu?\"\"\")\n",
        "print(f\"Jawaban: {result.jawaban}\")\n",
        "print(f\"Justifikasi: {result.justifikasi}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "536b852f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentimen: positive\n",
            "Skor: 0.9\n",
            "Justifikasi: Kalimat mengandung ekspresi kebahagiaan ('sangat senang'), kondisi positif ('cuacanya cerah'), dan pencapaian baik ('promosi kerja'), yang semuanya berkontribusi pada sentimen positif.\n",
            "Kata kunci: ['senang', 'cerah', 'promosi']\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class SentimentAnalysis(BaseModel):\n",
        "    '''Analisis sentimen dari teks beserta justifikasi untuk klasifikasi sentimen tersebut.'''\n",
        "    sentiment: str = Field(description=\"Sentimen utama (positive, negative, neutral)\")\n",
        "    score: float = Field(description=\"Skor sentimen antara -1 dan 1\")\n",
        "    justifikasi: str = Field(description=\"Penjelasan mengapa teks diklasifikasikan sebagai sentimen tertentu\")\n",
        "    keywords: list[str] = Field(description=\"Kata-kunci penting yang mempengaruhi analisis sentimen\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(SentimentAnalysis)\n",
        "\n",
        "result = structured_llm.invoke(\"Saya sangat senang hari ini karena cuacanya cerah dan saya mendapat promosi kerja!\")\n",
        "print(f\"Sentimen: {result.sentiment}\")\n",
        "print(f\"Skor: {result.score}\")\n",
        "print(f\"Justifikasi: {result.justifikasi}\")\n",
        "print(f\"Kata kunci: {result.keywords}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "392404e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: 78.54\n",
            "Metode: Rumus Luas Lingkaran\n",
            "Langkah-langkah:\n",
            "1. 1. Gunakan rumus luas lingkaran: L = Ï€ Ã— rÂ²\n",
            "2. 2. Masukkan nilai jari-jari (r = 5) ke dalam rumus: L = Ï€ Ã— 5Â²\n",
            "3. 3. Hitung 5Â² = 25\n",
            "4. 4. Kalikan dengan Ï€ (gunakan Ï€ â‰ˆ 3.14): L = 3.14 Ã— 25\n",
            "5. 5. Hasil akhir: L = 78.54\n",
            "Verifikasi: Luas lingkaran dihitung dengan rumus L = Ï€ Ã— rÂ², dan hasilnya sudah sesuai dengan substitusi nilai jari-jari.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class MathSolution(BaseModel):\n",
        "    '''Solusi untuk masalah matematika beserta penjelasan langkah-demi-langkah.'''\n",
        "    jawaban: float = Field(description=\"Hasil akhir dari perhitungan matematika\")\n",
        "    langkah_langkah: list[str] = Field(description=\"Langkah-langkah dalam menyelesaikan masalah\")\n",
        "    metode: str = Field(description=\"Metode matematika yang digunakan\")\n",
        "    verifikasi: str = Field(description=\"Verifikasi bahwa jawaban benar\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(MathSolution)\n",
        "\n",
        "result = structured_llm.invoke(\"Hitung luas lingkaran dengan jari-jari 5 cm, tunjukkan langkah-langkahnya.\")\n",
        "print(f\"Jawaban: {result.jawaban}\")\n",
        "print(f\"Metode: {result.metode}\")\n",
        "print(f\"Langkah-langkah:\")\n",
        "for i, langkah in enumerate(result.langkah_langkah, 1):\n",
        "    print(f\"{i}. {langkah}\")\n",
        "print(f\"Verifikasi: {result.verifikasi}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "511d9192",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Judul: Dunia Baru\n",
            "Penulis: Aldous Huxley\n",
            "Genre: Fiksi Ilmiah\n",
            "Rating: 8.5\n",
            "Target Pembaca: Pembaca muda dengan minat teknologi\n",
            "Alasan Rekomendasi:\n",
            "- Menyajikan gambaran masa depan yang dipenuhi kemajuan teknologi dan implikasi sosialnya\n",
            "- Mendorong pemikiran kritis tentang penggunaan teknologi dalam kehidupan sehari-hari\n",
            "- Kisahnya relevan dengan perkembangan dunia teknologi saat ini\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class BookRecommendation(BaseModel):\n",
        "    '''Rekomendasi buku beserta alasan-alasan untuk merekomendasikannya.'''\n",
        "    judul: str = Field(description=\"Judul buku yang direkomendasikan\")\n",
        "    penulis: str = Field(description=\"Nama penulis buku\")\n",
        "    genre: str = Field(description=\"Genre utama buku\")\n",
        "    rating: float = Field(description=\"Rating buku dari 1-10\")\n",
        "    alasan_rekomendasi: list[str] = Field(description=\"Alasan-alasan mengapa buku ini direkomendasikan\")\n",
        "    target_pembaca: str = Field(description=\"Jenis pembaca yang cocok untuk buku ini\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(BookRecommendation)\n",
        "\n",
        "result = structured_llm.invoke(\"Rekomendasikan sebuah buku fiksi ilmiah terbaik untuk pembaca muda dengan minat teknologi.\")\n",
        "print(f\"Judul: {result.judul}\")\n",
        "print(f\"Penulis: {result.penulis}\")\n",
        "print(f\"Genre: {result.genre}\")\n",
        "print(f\"Rating: {result.rating}\")\n",
        "print(f\"Target Pembaca: {result.target_pembaca}\")\n",
        "print(f\"Alasan Rekomendasi:\")\n",
        "for alasan in result.alasan_rekomendasi:\n",
        "    print(f\"- {alasan}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6a9ced",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negara: Indonesia\n",
            "Ibukota: Jakarta\n",
            "Populasi: 273,500,000\n",
            "Bahasa Utama: Bahasa Indonesia\n",
            "Informasi Unik:\n",
            "- Indonesia merupakan negara kepulauan terbesar di dunia.\n",
            "- Memiliki lebih dari 17.000 pulau.\n",
            "- Rawan terhadap bencana alam seperti gempa bumi, tsunami, dan banjir.\n",
            "Justifikasi: Indonesia rawan banjir karena letak geografisnya yang dekat dengan garis khatulistiwa menyebabkan musim hujan yang intensitas tinggi, ditambah lagi dengan kerusakan hutan dan buruknya sistem drainase di beberapa wilayah.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class GeoAnalysis(BaseModel):\n",
        "    '''Analisis geografis tentang lokasi beserta justifikasi untuk informasi tersebut.'''\n",
        "    negara: str = Field(description=\"Nama negara yang dianalisis\")\n",
        "    ibukota: str = Field(description=\"Ibukota dari negara tersebut\")\n",
        "    populasi: int = Field(description=\"Perkiraan jumlah penduduk\")\n",
        "    bahasa_utama: str = Field(description=\"Bahasa resmi atau paling umum digunakan\")\n",
        "    informasi_unik: list[str] = Field(description=\"Fakta-fakta unik atau menarik tentang negara tersebut\")\n",
        "    justifikasi: str = Field(description=\"Justifikasi untuk informasi yang disediakan\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(GeoAnalysis)\n",
        "\n",
        "result = structured_llm.invoke(\"Berikan informasi lengkap tentang  indonesia beserta fakta-fakta unik dan alasannya.\")\n",
        "print(f\"Negara: {result.negara}\")\n",
        "print(f\"Ibukota: {result.ibukota}\")\n",
        "print(f\"Populasi: {result.populasi:,}\")\n",
        "print(f\"Bahasa Utama: {result.bahasa_utama}\")\n",
        "print(f\"Informasi Unik:\")\n",
        "for info in result.informasi_unik:\n",
        "    print(f\"- {info}\")\n",
        "print(f\"Justifikasi: {result.justifikasi}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5e7dd162",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Penghasilan: Rp 10,000,000\n",
            "Total Pengeluaran: Rp 8,500,000\n",
            "Surplus/Defisit: Rp 1,500,000\n",
            "Kategori Pengeluaran Tertinggi: kontrak rumah\n",
            "Saran Penghematan:\n",
            "- Pertimbangkan untuk mencari opsi tempat tinggal yang lebih terjangkau\n",
            "- Kurangi frekuensi makan di luar\n",
            "- Gunakan transportasi umum\n",
            "Justifikasi: \"Pengeluaran terbesar digunakan untuk kontrak rumah, yang memakan hampir setengah dari penghasilan. Ada potensi penghematan signifikan di sini.\"\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class FinancialAnalysis(BaseModel):\n",
        "    '''Analisis keuangan pribadi beserta rekomendasi pengelolaan keuangan.'''\n",
        "    total_penghasilan: float = Field(description=\"Total penghasilan bulanan\")\n",
        "    total_pengeluaran: float = Field(description=\"Total pengeluaran bulanan\")\n",
        "    surplus_defisit: float = Field(description=\"Selisih antara penghasilan dan pengeluaran\")\n",
        "    kategori_pengeluaran_tertinggi: str = Field(description=\"Kategori pengeluaran dengan nilai tertinggi\")\n",
        "    saran_penghematan: list[str] = Field(description=\"Saran-saran untuk menghemat pengeluaran\")\n",
        "    justifikasi: str = Field(description=\"Justifikasi untuk analisis dan saran yang diberikan\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(FinancialAnalysis)\n",
        "\n",
        "result = structured_llm.invoke(\"Analisis keuangan berdasarkan penghasilan Rp 10.000.000/bulan, dengan pengeluaran Rp 8.500.000/bulan (Rp 4.000.000 untuk kontrak rumah, Rp 2.000.000 untuk makanan, Rp 1.500.000 untuk transportasi, Rp 1.000.000 untuk hiburan).\")\n",
        "print(f\"Total Penghasilan: Rp {result.total_penghasilan:,.0f}\")\n",
        "print(f\"Total Pengeluaran: Rp {result.total_pengeluaran:,.0f}\")\n",
        "print(f\"Surplus/Defisit: Rp {result.surplus_defisit:,.0f}\")\n",
        "print(f\"Kategori Pengeluaran Tertinggi: {result.kategori_pengeluaran_tertinggi}\")\n",
        "print(f\"Saran Penghematan:\")\n",
        "for saran in result.saran_penghematan:\n",
        "    print(f\"- {saran}\")\n",
        "print(f\"Justifikasi: {result.justifikasi}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dae95206",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nama Karyawan: Andi Pratama\n",
            "Skor Kinerja: 4.0/5\n",
            "Kekuatan:\n",
            "- Produktivitas tinggi\n",
            "- Kemampuan kolaborasi yang baik\n",
            "Area Pengembangan:\n",
            "- Keterampilan presentasi\n",
            "- Manajemen waktu\n",
            "Rekomendasi Pelatihan:\n",
            "- Pelatihan Presentasi Efektif\n",
            "- Workshop Manajemen Waktu\n",
            "Justifikasi Penilaian: Karyawan menunjukkan kinerja yang sangat baik dalam hal produktivitas dan kerja sama tim. Namun, peningkatan dalam keterampilan presentasi dan manajemen waktu akan semakin meningkatkan efektivitasnya dalam peran saat ini.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class PerformanceReview(BaseModel):\n",
        "    '''Evaluasi kinerja karyawan beserta justifikasi dan rekomendasi pengembangan.'''\n",
        "    nama_karyawan: str = Field(description=\"Nama lengkap karyawan yang dievaluasi\")\n",
        "    skor_kinerja: float = Field(description=\"Skor kinerja dari 1-5\")\n",
        "    kekuatan: list[str] = Field(description=\"Aspek-aspek kekuatan karyawan\")\n",
        "    area_pengembangan: list[str] = Field(description=\"Area yang perlu dikembangkan\")\n",
        "    rekomendasi_pelatihan: list[str] = Field(description=\"Rekomendasi pelatihan untuk meningkatkan kinerja\")\n",
        "    justifikasi_penilaian: str = Field(description=\"Justifikasi untuk penilaian yang diberikan\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(PerformanceReview)\n",
        "\n",
        "result = structured_llm.invoke(\"Evaluasi karyawan bernama Andi Pratama yang bekerja sebagai developer selama 2 tahun. Dia produktif, kolaboratif, namun perlu meningkatkan keterampilan presentasi dan manajemen waktu.\")\n",
        "print(f\"Nama Karyawan: {result.nama_karyawan}\")\n",
        "print(f\"Skor Kinerja: {result.skor_kinerja}/5\")\n",
        "print(f\"Kekuatan:\")\n",
        "for kekuatan in result.kekuatan:\n",
        "    print(f\"- {kekuatan}\")\n",
        "print(f\"Area Pengembangan:\")\n",
        "for area in result.area_pengembangan:\n",
        "    print(f\"- {area}\")\n",
        "print(f\"Rekomendasi Pelatihan:\")\n",
        "for rekomendasi in result.rekomendasi_pelatihan:\n",
        "    print(f\"- {rekomendasi}\")\n",
        "print(f\"Justifikasi Penilaian: {result.justifikasi_penilaian}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6d1577b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nama Makanan: Nasi Goreng Sederhana\n",
            "Tingkat Kesulitan: mudah\n",
            "Waktu Memasak: 15 menit\n",
            "Kalori per Porsi: ~350 kalori\n",
            "Bahan Utama:\n",
            "- nasi putih\n",
            "- telur\n",
            "- bawang merah\n",
            "- bawang putih\n",
            "- kecap manis\n",
            "- garam\n",
            "- merica\n",
            "Langkah Memasak:\n",
            "1. Tumis bawang merah dan bawang putih hingga harum.\n",
            "2. Masukkan telur, aduk hingga matang.\n",
            "3. Tambahkan nasi putih, aduk rata.\n",
            "4. Beri kecap manis, garam, dan merica secukupnya.\n",
            "5. Aduk hingga semua bahan tercampur rata dan matang.\n",
            "Justifikasi: Resep ini mudah diikuti dan menggunakan bahan-bahan yang umum serta mudah ditemukan.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class RecipeAnalysis(BaseModel):\n",
        "    '''Analisis resep makanan beserta informasi nutrisi dan instruksi memasak.'''\n",
        "    nama_makanan: str = Field(description=\"Nama makanan yang dianalisis\")\n",
        "    tingkat_kesulitan: str = Field(description=\"Tingkat kesulitan memasak (mudah, sedang, sulit)\")\n",
        "    waktu_memasak: int = Field(description=\"Waktu total memasak dalam menit\")\n",
        "    kalori_per_porsi: int = Field(description=\"Jumlah kalori per porsi\")\n",
        "    bahan_utama: list[str] = Field(description=\"Bahan-bahan utama yang digunakan\")\n",
        "    langkah_memasak: list[str] = Field(description=\"Langkah-langkah cara memasak\")\n",
        "    justifikasi: str = Field(description=\"Justifikasi untuk analisis resep\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(RecipeAnalysis)\n",
        "\n",
        "result = structured_llm.invoke(\"Buatkan analisis resep untuk nasi goreng sederhana yang cocok untuk pemula.\")\n",
        "print(f\"Nama Makanan: {result.nama_makanan}\")\n",
        "print(f\"Tingkat Kesulitan: {result.tingkat_kesulitan}\")\n",
        "print(f\"Waktu Memasak: {result.waktu_memasak} menit\")\n",
        "print(f\"Kalori per Porsi: ~{result.kalori_per_porsi} kalori\")\n",
        "print(f\"Bahan Utama:\")\n",
        "for bahan in result.bahan_utama:\n",
        "    print(f\"- {bahan}\")\n",
        "print(f\"Langkah Memasak:\")\n",
        "for i, langkah in enumerate(result.langkah_memasak, 1):\n",
        "    print(f\"{i}. {langkah}\")\n",
        "print(f\"Justifikasi: {result.justifikasi}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "453a2f81",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jenis Perangkat: Laptop\n",
            "Gejala Masalah: Laptop tidak bisa menyala dan lampu indikator tidak menyala sama sekali setelah charger dicolokkan.\n",
            "Tingkat Keparahan: sedang\n",
            "Kemungkinan Penyebab:\n",
            "- Charger rusak atau tidak berfungsi.\n",
            "- Kabel power rusak.\n",
            "- Baterai rusak atau bocor.\n",
            "- Motherboard mengalami kerusakan.\n",
            "Solusi yang Disarankan:\n",
            "- Coba charger lain yang kompatibel untuk memastikan charger berfungsi.\n",
            "- Periksa kabel power apakah ada yang putus atau rusak.\n",
            "- Lepaskan baterai (jika dapat dilepas) dan coba nyalakan laptop langsung menggunakan charger.\n",
            "- Bawa ke teknisi untuk pemeriksaan lebih lanjut jika semua langkah di atas tidak berhasil.\n",
            "Justifikasi Diagnosis: Gejala ini menunjukkan bahwa laptop tidak menerima daya dari charger, kemungkinan besar terjadi pada komponen sumber daya seperti charger, baterai, atau motherboard.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class TechnicalDiagnosis(BaseModel):\n",
        "    '''Diagnosis teknis untuk masalah perangkat elektronik beserta solusi.'''\n",
        "    jenis_perangkat: str = Field(description=\"Jenis perangkat yang bermasalah\")\n",
        "    gejala_masalah: str = Field(description=\"Gejala atau tanda-tanda masalah yang dialami\")\n",
        "    kemungkinan_penyebab: list[str] = Field(description=\"Kemungkinan penyebab masalah\")\n",
        "    solusi_yang_disarankan: list[str] = Field(description=\"Langkah-langkah solusi yang disarankan\")\n",
        "    tingkat_keparahan: str = Field(description=\"Tingkat keparahan masalah (ringan, sedang, berat)\")\n",
        "    justifikasi_diagnosis: str = Field(description=\"Justifikasi untuk diagnosis yang diberikan\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(TechnicalDiagnosis)\n",
        "\n",
        "result = structured_llm.invoke(\"Laptop tidak bisa menyala meskipun sudah dicolokkan charger. Lampu indikator tidak menyala sama sekali.\")\n",
        "print(f\"Jenis Perangkat: {result.jenis_perangkat}\")\n",
        "print(f\"Gejala Masalah: {result.gejala_masalah}\")\n",
        "print(f\"Tingkat Keparahan: {result.tingkat_keparahan}\")\n",
        "print(f\"Kemungkinan Penyebab:\")\n",
        "for penyebab in result.kemungkinan_penyebab:\n",
        "    print(f\"- {penyebab}\")\n",
        "print(f\"Solusi yang Disarankan:\")\n",
        "for solusi in result.solusi_yang_disarankan:\n",
        "    print(f\"- {solusi}\")\n",
        "print(f\"Justifikasi Diagnosis: {result.justifikasi_diagnosis}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31dc00f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'cherry']\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "parser = CommaSeparatedListOutputParser()\n",
        "items = parser.invoke(\"apple, banana, cherry\")\n",
        "print(items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "854d4b17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Hello! Ù©(â—•â€¿â—•ï½¡)Û¶ How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 11, 'total_tokens': 31, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-23dbb519-5183-4d58-a7e6-bd674683567f-0' usage_metadata={'input_tokens': 11, 'output_tokens': 20, 'total_tokens': 31}\n",
            "[AIMessage(content='Hello! Ù©(â—•â€¿â—•ï½¡)Û¶ How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 11, 'total_tokens': 31, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-38d60167-936f-4394-aa81-d7878ee1f15a-0', usage_metadata={'input_tokens': 11, 'output_tokens': 20, 'total_tokens': 31}), AIMessage(content='Goodbye! If you have any more questions or need help in the future, feel free to reach out. Have a great day! ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 11, 'total_tokens': 40, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ecaac13b-a7b5-4e96-8bed-5e0cffabcef4-0', usage_metadata={'input_tokens': 11, 'output_tokens': 29, 'total_tokens': 40})]\n",
            "content='Good' id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n",
            "content='bye! Take' id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n",
            "content=' care and' id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n",
            "content=' have' id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n",
            "content=' a great day!' id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n",
            "content=' ðŸ˜Š' id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n",
            "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-coder-plus'} id='run-1e12936a-1a2d-4019-b915-3dd52572309e'\n"
          ]
        }
      ],
      "source": [
        "completion = llm.invoke('Hi there!')\n",
        "print(completion)\n",
        "\n",
        "\n",
        "completions = llm.batch(['Hi there!', 'Bye!'])\n",
        "print(completions)\n",
        "\n",
        "for token in llm.stream('Bye!'):\n",
        "    print(token)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "decbfce8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Here are the main categories of model providers that offer LLMs:\\n\\n## Major Tech Companies\\n- **OpenAI** - GPT models (GPT-3, GPT-3.5, GPT-4)\\n- **Google** - Gemini (formerly Bard), PaLM, and other models\\n- **Meta** - Llama series (Llama, Llama2, Llama3)\\n- **Microsoft** - Integration with OpenAI models, Phi series\\n- **Anthropic** - Claude models\\n- **Amazon** - Bedrock service with various models\\n- **IBM** - WatsonX\\n\\n## Cloud Providers\\n- **AWS** - Bedrock, SageMaker\\n- **Google Cloud** - Vertex AI\\n- **Microsoft Azure** - Azure OpenAI Service\\n- **Oracle** - OCI Generative AI\\n- **Alibaba Cloud** - Tongyi Lab models\\n\\n## Specialized AI Companies\\n- **Cohere** - Command and other models\\n- **Hugging Face** - Model hub and inference API\\n- **Together AI** - Various open and commercial models\\n- **Mistral AI** - Mistral models\\n- **Perplexity** - PPLX models\\n- **Character.AI** - Custom character models\\n\\n## Open Source/Research Organizations\\n- **EleutherAI** - GPT-NeoX, Pythia\\n- **Stability AI** - StableLM\\n- **Various universities and research labs**\\n\\nThe landscape is rapidly evolving with new providers and models launching regularly. Many companies also offer both hosted APIs and on-premises deployment options.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 330, 'prompt_tokens': 27, 'total_tokens': 357, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-899e46dd-f142-404a-b4f6-64d390f914fd-0', usage_metadata={'input_tokens': 27, 'output_tokens': 330, 'total_tokens': 357})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "# the building blocks\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    ('system', 'You are a helpful assistant.'),\n",
        "    ('human', '{question}'),\n",
        "])\n",
        "\n",
        "\n",
        "# combine them in a function\n",
        "# @chain decorator adds the same Runnable interface for any function you write\n",
        "\n",
        "@chain\n",
        "def chatbot(values):\n",
        "    prompt = template.invoke(values)\n",
        "    return llm.invoke(prompt)\n",
        "\n",
        "# use it\n",
        "\n",
        "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3d3e100b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Here' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' are the' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' main' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' categories' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' of model providers that' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' offer LLMs' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=':\\n\\n## Major Tech' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Companies\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='OpenAI** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' GPT models (' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='GPT-3' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=', GPT-' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='3' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='.5, G' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='PT' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='-4)\\n-' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' **Google** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Gemini (formerly Bard' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='), PaLM,' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' and other models\\n' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='Meta** - L' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='lama series (L' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='lama,' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Llama2,' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Llama3' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=')\\n- **Microsoft' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='** - Integration with' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Open' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='AI models, Phi' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' series\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='Anth' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ropic** - Claude' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' models\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='Amazon' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='** - Bedrock' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' service' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' with various foundation models' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='IBM** - Watson' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='X with open-source' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' models\\n\\n##' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Cloud Providers\\n-' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' **Azure' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='** - Azure Open' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='AI Service\\n-' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' **AWS' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='** - Amazon Bed' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='rock, SageMaker' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' JumpStart\\n-' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' **Google' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Cloud** - Vertex' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' AI\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='Oracle' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='** - Oracle Cloud' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Infrastructure' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Generative AI\\n\\n' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='## Open Source &' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Academic\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='H' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ugging Face** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Hub with thousands of' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' open' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' models\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='Ele' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='utherAI** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' G' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='PT-NeoX' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=', Pythia' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' series\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='Together AI** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Host' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ed open-source models' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='\\n' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='- **Mist' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ral AI** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Open-weight models\\n' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='- **Datab' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ricks** - D' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='olly and other open' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' models\\n\\n## Special' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ized/Enterprise\\n' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='- **Coh' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ere** - F' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ocused on enterprise applications' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='\\n- **AI' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='21 Labs**' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' - Jurassic' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' series\\n- **' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='St' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='ability AI** -' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' Focus' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' on multimodal models' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='\\n-' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' **Perplexity' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='** - Search-focused' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' AI models\\n\\nThe' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' landscape is rapidly evolving' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' with' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' new providers and models' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' launching regularly. Many' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' companies also develop proprietary' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' models for internal use' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' without' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content=' offering them as services' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='.' id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n",
            "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-coder-plus'} id='run-48e1e257-3be1-4752-9b15-4746018b642a'\n"
          ]
        }
      ],
      "source": [
        "@chain\n",
        "def chatbot(values):\n",
        "    prompt = template.invoke(values)\n",
        "    for token in llm.stream(prompt):\n",
        "        yield token\n",
        "\n",
        "for part in chatbot.stream({\"question\": \"Which model providers offer LLMs?\"}):\n",
        "    print(part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "15117488",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Here are the main categories of LLM (Large Language Model) providers:\\n\\n## Major Tech Companies\\n- **OpenAI** - GPT-3, GPT-3.5, GPT-4, ChatGPT\\n- **Google** - Gemini (formerly Bard), PaLM, LaMDA\\n- **Meta** - Llama series (Llama, Llama2, Llama3)\\n- **Microsoft** - Azure OpenAI Service (hosting OpenAI models)\\n- **Anthropic** - Claude series\\n- **Amazon** - Amazon Bedrock, Titan models\\n- **IBM** - WatsonX\\n\\n## Chinese Tech Companies\\n- **Baidu** - ERNIE Bot\\n- **Alibaba** - Qwen (Tongyi Qianwen)\\n- **Tencent** - HunYuan\\n- **ByteDance** - Doubao\\n- **SenseTime** - SenseNova\\n\\n## Specialized AI Companies\\n- **Cohere** - Command series\\n- **Hugging Face** - Various open-source models\\n- **Stability AI** - StableLM\\n- **Together AI** - Various hosted models\\n\\n## Cloud Platforms Offering LLM Services\\n- **Azure** - Azure OpenAI Service\\n- **AWS** - Amazon Bedrock\\n- **Google Cloud** - Vertex AI\\n- **IBM Cloud** - WatsonX\\n\\nThe landscape is rapidly evolving with new models and providers launching regularly. Some focus on general-purpose models while others specialize in specific domains or use cases.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 312, 'prompt_tokens': 27, 'total_tokens': 339, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b1de5878-9297-49ac-a5a3-c44907193b98-0', usage_metadata={'input_tokens': 27, 'output_tokens': 312, 'total_tokens': 339})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@chain\n",
        "async def chatbot(values):\n",
        "    prompt = await template.ainvoke(values)\n",
        "    return await llm.ainvoke(prompt)\n",
        "\n",
        "await chatbot.ainvoke({\"question\": \"Which model providers offer LLMs?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bcd297b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Here are the main categories of model providers that offer LLMs:\\n\\n## Cloud/Enterprise Providers\\n- **OpenAI** - GPT models (GPT-4, GPT-3.5, etc.)\\n- **Google** - Gemini, PaLM, Bard\\n- **Anthropic** - Claude models\\n- **Meta** - Llama family (Llama, Llama2, Llama3)\\n- **Microsoft** - Azure OpenAI integration, Phi models\\n- **Amazon** - Bedrock (Anthropic, AI21, Cohere models), Titan models\\n- **IBM** - WatsonX, Granite models\\n\\n## Specialized AI Companies\\n- **Cohere** - Command, Embed models\\n- **AI21 Labs** - Jurassic series\\n- **Stability AI** - Focus on multimodal models\\n- **Mistral AI** - Mistral models\\n- **x.ai** - Grok models\\n\\n## Open Source/Foundation Models\\n- **Hugging Face** - Hub for many open models (Meta's Llama, others)\\n- **EleutherAI** - GPT-NeoX, Pythia\\n- **Together AI** - Hosts various open models\\n- **Databricks** - Dolly, training tools\\n\\n## Regional/Other Providers\\n- **Alibaba Cloud** - Qwen models\\n- **Baidu** - ERNIE Bot\\n- **Tencent** - HunYuan\\n- **Samsung** - Gauss models\\n\\nThe landscape is rapidly evolving with new providers and models launching regularly. Some focus on proprietary models while others emphasize open-source approaches.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 335, 'prompt_tokens': 27, 'total_tokens': 362, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e5623559-edc2-45e1-9254-4c9bb6099b1d-0', usage_metadata={'input_tokens': 27, 'output_tokens': 335, 'total_tokens': 362})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# the building blocks\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    ('system', 'You are a helpful assistant.'),\n",
        "    ('human', '{question}'),\n",
        "])\n",
        "\n",
        "\n",
        "# combine them with the | operator\n",
        "\n",
        "chatbot = template | llm\n",
        "\n",
        "# use it\n",
        "\n",
        "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0cbffe84",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Here' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' are the' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' main' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' categories' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' of model providers that' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' offer LLMs' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=':\\n\\n## Cloud/A' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='I Platform Providers\\n' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='- **Open' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='AI** - G' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='PT' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' models (GPT' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='-4' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=', GPT-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='3.' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='5, etc.)\\n' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='- **Google' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='** - Gemini,' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' PaLM, and' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' other models via Vertex' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' AI\\n- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Anth' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='ropic** - Claude' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' models\\n- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Meta' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='** - Llama' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' family' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' (Llama,' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Llama2,' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Llama3' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=')\\n- **Microsoft' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='** - Azure Open' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='AI Service, Phi' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' models\\n- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Amazon** - Bed' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='rock with various foundation' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' models\\n- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='IBM** - wat' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='sonx.ai platform' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='\\n\\n## Tech Giants' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' & Large Companies\\n' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Apple** - On' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='-device models for Siri' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=', iOS features\\n' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='- **N' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='VIDIA** - Ne' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Mo framework, cu' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='DF LLMs' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='\\n- **Sales' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='force** - Einstein' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' GPT models\\n' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='- **C' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='ohere** -' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Special' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='ized enterprise LLM' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='s\\n-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' **Hugging Face' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='** -' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Model hub and inference' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' API\\n- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='St' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='ability AI** -' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Language' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' models alongside image generation' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='\\n\\n## Open Source' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' & Academic\\n-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' **Various' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' researchers** via H' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='ugging Face\\n-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' **University labs**' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' and' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' research institutions\\n-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Independent developers** creating' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' open models\\n\\n##' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Special' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='ized/Enterprise Providers' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='\\n- **Per' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='plexity AI**' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' - Search' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='-focused models\\n-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' **M' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='istral AI**' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' - Open' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='-weight European models\\n' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='- **' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='Databricks**' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' - D' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='olly and other models' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='\\n-' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' **Many others**' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' focusing' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' on specific use cases' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='\\n\\nThe landscape' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' is rapidly evolving with' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' new entrants regularly' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' joining the market.' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' Would' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' you like more details' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' about any specific provider' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' or type' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content=' of LLM offering' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='?' id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n",
            "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-coder-plus'} id='run-13bf7a3a-66b5-4700-a6a6-088eba0379b3'\n"
          ]
        }
      ],
      "source": [
        "chatbot = template | llm\n",
        "\n",
        "for part in chatbot.stream({ \"question\": \"Which model providers offer LLMs?\"}):\n",
        "    print(part)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "learning-langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
