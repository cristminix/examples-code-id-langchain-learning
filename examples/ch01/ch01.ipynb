{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "generic-configuration",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generic OpenAI-compatible endpoint using ChatOpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage,SystemMessage\n",
        "import os\n",
        "default_model_name = os.environ[\"OPENAI_MODEL\"]\n",
        "llm = ChatOpenAI(model=default_model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6d58b398",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is **Paris**.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 27, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 7}, 'words': 52}, 'model_name': 'zai', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f47a941d-fd4f-4932-83c5-4de600cc733c-0')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [HumanMessage(\"What is the capital of France?\")]\n",
        "llm.invoke(messages) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dca7c598",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris!!!', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 32, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}, 'words': 50}, 'model_name': 'zai', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-16b4fee3-44e8-4b66-ae02-9a95642c0913-0')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "system_msg = SystemMessage(\n",
        "    '''You are a helpful assistant that responds to questions with three\n",
        "        exclamation marks.'''\n",
        ")\n",
        "messages = [system_msg,HumanMessage(\"What is the capital of France?\")]\n",
        "llm.invoke(messages) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3f5a0200",
      "metadata": {},
      "outputs": [],
      "source": [
        "context=\"\"\"Kemajuan terbaru dalam NLP didorong oleh Large Language Models\n",
        "(LLM). Model-model ini mengungguli model-model yang lebih kecil dan telah\n",
        "menjadi sangat berharga bagi para pengembang yang membuat aplikasi dengan\n",
        "kemampuan NLP. Pengembang dapat mengakses model-model ini melalui library\n",
        "`transformers` dari Hugging Face, atau dengan memanfaatkan layanan dari OpenAI\n",
        "dan Cohere melalui library `openai` dan `cohere`.\"\"\"\n",
        "question=\"Penyedia model mana saja yang menawarkan LLM?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ae304344",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Berdasarkan konteks yang diberikan, penyedia model yang menawarkan LLM antara lain:\n",
            "\n",
            "1. **Hugging Face** (melalui library `transformers`)\n",
            "2. **OpenAI** (melalui library `openai`)\n",
            "3. **Cohere** (melalui library `cohere`)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    ('system', '''Answer the question based on the context below. If the\n",
        "        question cannot be answered using the information provided, answer with\n",
        "        \"I don\\'t know\".'''),\n",
        "    ('human', 'Context: {context}'),\n",
        "    ('human', 'Question: {question}'),\n",
        "])\n",
        "chain = template | llm\n",
        "result=chain.invoke({\n",
        "    \"context\":context,\n",
        "    \"question\":question\n",
        "})\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "02ac20e9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Berdasarkan konteks yang diberikan, penyedia model yang menawarkan LLM antara lain:\n",
            "\n",
            "1. **Hugging Face** - melalui library `transformers`.\n",
            "2. **OpenAI** - melalui layanan dan library `openai`.\n",
            "3. **Cohere** - melalui layanan dan library `cohere`.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = PromptTemplate.from_template(\"\"\"Jawab pertanyaan berdasarkan konteks\n",
        "    di bawah ini. Jika pertanyaan tidak dapat dijawab menggunakan informasi\n",
        "    yang diberikan, jawab dengan \"Saya tidak tahu\".\n",
        "\n",
        "Konteks: {context}\n",
        "\n",
        "Pertanyaan: {question}\n",
        "\n",
        "Jawaban: \"\"\")\n",
        "\n",
        "result=chain.invoke({\n",
        "    \"context\":context,\n",
        "    \"question\":question\n",
        "})\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3eae870b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "JawabanDenganJustifikasi(jawaban='Keduanya sama berat.', justifikasi='Satu pon batu bata dan satu pon bulu memiliki berat yang sama karena satuan \"pon\" menyatakan berat yang identik, terlepas dari jenis materialnya. Meskipun volume bulu jauh lebih besar daripada batu bata, berat keduanya tetap sama yaitu satu pon.')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "\n",
        "class JawabanDenganJustifikasi(BaseModel):\n",
        "    '''Jawaban atas pertanyaan pengguna beserta justifikasi untuk jawaban tersebut.'''\n",
        "    jawaban: str\n",
        "    '''Jawaban atas pertanyaan pengguna'''\n",
        "    justifikasi: str\n",
        "    '''Justifikasi untuk jawaban'''\n",
        "\n",
        "structured_llm = llm.with_structured_output(JawabanDenganJustifikasi)\n",
        "\n",
        "structured_llm.invoke(\"\"\"Mana yang lebih berat, satu pon batu bata atau satu pon bulu?\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "learning-langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
